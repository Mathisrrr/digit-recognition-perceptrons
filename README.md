# Digit & Character Recognition Perceptrons ðŸ”¢ðŸ§ 

**Academic Project â€“ Machine Learning (L3-S6)**  

This repository contains **two implementations** for character recognition:

1. A **simple perceptron** for handwritten digits (MNIST dataset)  
2. A **multi-layer perceptron (MLP)** for all AZERTY keyboard characters  

Additionally, the repository includes a **document detailing the search for optimal hyperparameters**, which explains the reasoning behind parameter choices and their impact on model performance.

---

## ðŸŽ¯ Objectives

- Implement and compare a **simple perceptron** and a **MLP**.  
- Explore the effects of hyperparameters (learning rate, number of iterations, etc.) on model accuracy.  
- Understand core machine learning concepts: weights, bias, activation functions, backpropagation.  
- Apply best practices for clean, modular, and reproducible Python code.  
- Extend recognition from digits to **full AZERTY keyboard characters** with the MLP.

---

## ðŸ§  Implemented Solution

- **Simple Perceptron**: Manual implementation for digit classification using MNIST.  
- **MLP**: Multi-layer perceptron capable of recognizing all AZERTY keyboard characters.  
- **Hyperparameter optimization**: Systematic exploration to find the best configuration for learning rate, number of epochs, and training sample size.  

---

## ðŸ›  Technologies & Tools

- **Python 3.11**  
- **NumPy** for matrix and vector operations  
- **Pandas** for data handling  
- **Matplotlib** for visualization (optional)  

---

## ðŸ§© Features

- Train and evaluate both **simple perceptron** and **MLP** models.  
- Recognize digits (MNIST) and full AZERTY keyboard characters.  
- Compare performance metrics between models.  
- Modular code allowing easy adjustment of hyperparameters.  
- Reproducible results with preprocessed data and clear instructions.

---

## ðŸš€ How to Run

Before running the MLP, you must extract the train and test datasets using the extract6 script and the provided archive files
